{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Redundant Files for Some Buildings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Redundant files for Building 0 to 80\n",
    "# Redundant files include:\n",
    "# beam_set.pkl\n",
    "# building.pkl\n",
    "# column_set.pkl\n",
    "# connection_set.pkl\n",
    "# ColumnBeamRatio.csv\n",
    "\n",
    "import os\n",
    "\n",
    "base_directory = 'C:\\\\Users\\\\XINGQUAN GUAN\\\\Documents\\\\GitHub\\\\SeismicDesignModule'\n",
    "file_list = ['beam_set.pkl', 'building.pkl', 'column_set.pkl', 'connection_set.pkl', 'ColumnBeamRatio.csv']\n",
    "\n",
    "building_ID = range(0, 81, 1)\n",
    "\n",
    "for ID in building_ID:\n",
    "    for file in file_list:\n",
    "        target_folder = base_directory + '\\\\BuildingData' + '\\\\Building_' + str(ID)\n",
    "        os.chdir(target_folder)\n",
    "        if(os.path.exists(file)):\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename .csv Files Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the files:\n",
    "# ColumnAxialDCRatio.csv -> OptimalColumnAxialDCRatio.csv\n",
    "# ColumnShearDCRatio.csv -> OptimalColumnShearDCRatio.csv\n",
    "# ColumnFlexuralDCRatio.csv -> OptimalFlexuralDCRatio.csv\n",
    "\n",
    "import os\n",
    "\n",
    "base_directory = 'C:\\\\Users\\\\XINGQUAN GUAN\\\\Documents\\\\GitHub\\\\SeismicDesignModule'\n",
    "file_list = ['ColumnAxialDCRatio.csv', 'ColumnShearDCRatio.csv', 'ColumnFlexuralDCRatio.csv']\n",
    "new_file_list = ['OptimalColumnAxialDCRatio.csv', 'OptimalColumnShearDCRatio.csv', 'OptimalColumnFlexuralDCRatio.csv']\n",
    "\n",
    "building_ID = range(0, 566, 1)\n",
    "\n",
    "for ID in building_ID:\n",
    "    for indx in range(0, len(file_list)):\n",
    "        target_folder = base_directory + '\\\\BuildingData' + '\\\\Building_' + str(ID)\n",
    "        os.chdir(target_folder)\n",
    "        if (os.path.exists(file_list[indx])):\n",
    "            os.rename(file_list[indx], new_file_list[indx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Building Whose Output is not Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for ID in target_ID:\n",
    "    target_folder = base_directory + '\\\\BuildingData' + '\\\\Building_' + str(ID)\n",
    "    os.chdir(target_folder)\n",
    "    with open('optimal_connection_set.pkl', 'rb') as file1:\n",
    "        optimal_connection_set = pickle.load(file1)\n",
    "    with open('construction_connection_set.pkl', 'rb') as file2:\n",
    "        construction_connection_set = pickle.load(file2)\n",
    "    with open('optimal_building.pkl', 'rb') as file3:\n",
    "        building = pickle.load(file3)\n",
    "    # Create header\n",
    "    header = []\n",
    "    for bay in range(building.geometry['number of X bay']+1):\n",
    "        header.append('connection %s' % bay)\n",
    "    # Initialize the dataframe to store doubler plate thickness\n",
    "    optimal_doubler_plate = pd.DataFrame(columns=header)\n",
    "    construction_doubler_plate = pd.DataFrame(columns=header)\n",
    "    for row in range(building.geometry['number of story']):\n",
    "        for col in range(building.geometry['number of X bay']+1):\n",
    "            name = header[col]\n",
    "            optimal_doubler_plate.loc[row, name] = optimal_connection_set[row][col].doubler_plate_thickness\n",
    "            construction_doubler_plate.loc[row, name] = construction_connection_set[row][col].doubler_plate_thickness\n",
    "    optimal_doubler_plate.to_csv('OptimalDoublerPlate.csv', sep=',', index=False)\n",
    "    construction_doubler_plate.to_csv('ConstructionDoublerPlate.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Buildings Whose Story Drift > 2%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[81,\n",
       " 84,\n",
       " 87,\n",
       " 90,\n",
       " 93,\n",
       " 96,\n",
       " 99,\n",
       " 102,\n",
       " 105,\n",
       " 108,\n",
       " 111,\n",
       " 114,\n",
       " 117,\n",
       " 120,\n",
       " 123,\n",
       " 126,\n",
       " 129,\n",
       " 132,\n",
       " 135,\n",
       " 138,\n",
       " 141,\n",
       " 144,\n",
       " 147,\n",
       " 150,\n",
       " 153,\n",
       " 156,\n",
       " 159,\n",
       " 162,\n",
       " 165,\n",
       " 168,\n",
       " 171,\n",
       " 174,\n",
       " 177,\n",
       " 180,\n",
       " 183,\n",
       " 186,\n",
       " 189,\n",
       " 192,\n",
       " 195,\n",
       " 198,\n",
       " 201,\n",
       " 204,\n",
       " 207,\n",
       " 210,\n",
       " 213,\n",
       " 216,\n",
       " 219,\n",
       " 222,\n",
       " 225,\n",
       " 228,\n",
       " 231,\n",
       " 234,\n",
       " 237,\n",
       " 240,\n",
       " 243,\n",
       " 246,\n",
       " 249,\n",
       " 252,\n",
       " 255,\n",
       " 258,\n",
       " 261,\n",
       " 264,\n",
       " 267,\n",
       " 270,\n",
       " 273,\n",
       " 276,\n",
       " 279,\n",
       " 282,\n",
       " 285,\n",
       " 288,\n",
       " 291,\n",
       " 294,\n",
       " 297,\n",
       " 300,\n",
       " 303,\n",
       " 306,\n",
       " 309,\n",
       " 312,\n",
       " 315,\n",
       " 318,\n",
       " 321,\n",
       " 324,\n",
       " 327,\n",
       " 330,\n",
       " 333,\n",
       " 336,\n",
       " 339,\n",
       " 342,\n",
       " 345,\n",
       " 348,\n",
       " 351,\n",
       " 354,\n",
       " 357,\n",
       " 360,\n",
       " 363,\n",
       " 366,\n",
       " 369,\n",
       " 372,\n",
       " 375,\n",
       " 378,\n",
       " 381,\n",
       " 384,\n",
       " 387,\n",
       " 390,\n",
       " 393,\n",
       " 396,\n",
       " 399,\n",
       " 402,\n",
       " 405,\n",
       " 408,\n",
       " 411,\n",
       " 414,\n",
       " 417,\n",
       " 420,\n",
       " 423,\n",
       " 426,\n",
       " 429,\n",
       " 432,\n",
       " 435,\n",
       " 438,\n",
       " 441,\n",
       " 444,\n",
       " 447,\n",
       " 450,\n",
       " 453,\n",
       " 456,\n",
       " 459,\n",
       " 462,\n",
       " 465,\n",
       " 468,\n",
       " 471,\n",
       " 474,\n",
       " 477,\n",
       " 480,\n",
       " 483,\n",
       " 486,\n",
       " 489,\n",
       " 492,\n",
       " 495,\n",
       " 498,\n",
       " 501,\n",
       " 504,\n",
       " 507,\n",
       " 510,\n",
       " 513,\n",
       " 516,\n",
       " 519,\n",
       " 522,\n",
       " 525,\n",
       " 528,\n",
       " 531,\n",
       " 534,\n",
       " 537,\n",
       " 540,\n",
       " 543,\n",
       " 546,\n",
       " 549,\n",
       " 552,\n",
       " 555,\n",
       " 558,\n",
       " 561,\n",
       " 564]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base directory: where the SeismicDesignModule package is stored\n",
    "base_directory = 'C:\\\\Users\\\\61946\\\\Documents\\\\GitHub\\\\SeismicDesignModule'\n",
    "\n",
    "# Postprocessing folder path\n",
    "postprocessing_directory = base_directory + '\\\\Postprocessing\\\\SeismicDesign' \n",
    "\n",
    "# Preprocessing folder path\n",
    "preprocessing_directory = base_directory + '\\\\Preprocessing\\\\SeismicDesign'\n",
    "\n",
    "# Design results folder path\n",
    "design_directory = base_directory + '\\\\BuildingData'\n",
    "\n",
    "# Load the section database\n",
    "os.chdir(base_directory)\n",
    "with open('AllSectionDatabase.csv', 'r') as file:\n",
    "    SECTION_DATABASE = pd.read_csv(file, header=0)\n",
    "\n",
    "# Load the design sampling space\n",
    "os.chdir(preprocessing_directory)\n",
    "with open('DesignSheet2.csv', 'r') as file:\n",
    "    DESIGN_SPACE = pd.read_csv(file, header=0)\n",
    "\n",
    "# Find the building IDs that we are interested in.\n",
    "target_ID = []\n",
    "# except_ID = [1131, 1536] # for 14-story building\n",
    "except_ID = []\n",
    "row_number = DESIGN_SPACE.shape[0]\n",
    "for indx in range(row_number):\n",
    "    if DESIGN_SPACE.loc[indx, 'number of story'] == 5 and DESIGN_SPACE.loc[indx, 'column beam ratio'] == 1.0 \\\n",
    "    and DESIGN_SPACE.loc[indx, 'building ID'] not in except_ID \\\n",
    "    and DESIGN_SPACE.loc[indx, 'number of bay'] != 1:\n",
    "        target_ID.append(DESIGN_SPACE.loc[indx, 'building ID'])\n",
    "target_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_drift = []\n",
    "construction_drift = []\n",
    "optimal_story_exceptional_ID = []\n",
    "construction_story_exceptional_ID = []\n",
    "for ID in target_ID:\n",
    "    optimal_drift_per = []\n",
    "    construction_drift_per = []\n",
    "    target_path = design_directory + \"\\\\Building_\" + str(ID)\n",
    "    os.chdir(target_path)\n",
    "    with open('OptimalStoryDrift.csv', 'r') as file1:\n",
    "        OptimalDrift = pd.read_csv(file1, header=0)\n",
    "    with open('ConstructionDrift.csv', 'r') as file2:\n",
    "        ConstructionDrift = pd.read_csv(file2, header=0)\n",
    "    RowNumber = OptimalDrift.shape[0]\n",
    "    for story in range(RowNumber):\n",
    "        optimal_drift_per.append(OptimalDrift.loc[story, 'story drift']*5.5*1.1*100)\n",
    "        construction_drift_per.append(ConstructionDrift.loc[story, 'story drift']*5.5*1.1*100)\n",
    "    optimal_drift_per.append(OptimalDrift.loc[story, 'story drift']*5.5*1.1*100)\n",
    "    construction_drift_per.append(ConstructionDrift.loc[story, 'story drift']*5.5*1.1*100)\n",
    "    if (max(optimal_drift_per) >= 2):\n",
    "        optimal_story_exceptional_ID.append(ID)\n",
    "    if (max(construction_drift_per) >= 2):\n",
    "        construction_story_exceptional_ID.append(ID)\n",
    "    optimal_drift.append(optimal_drift_per)\n",
    "    construction_drift.append(construction_drift_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(optimal_story_exceptional_ID)\n",
    "print(construction_story_exceptional_ID)\n",
    "print(construction_drift)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Whether Missed Any Building Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1539,\n",
       " 1542,\n",
       " 1545,\n",
       " 1548,\n",
       " 1551,\n",
       " 1554,\n",
       " 1557,\n",
       " 1560,\n",
       " 1563,\n",
       " 1566,\n",
       " 1569,\n",
       " 1572,\n",
       " 1575,\n",
       " 1578,\n",
       " 1581,\n",
       " 1584,\n",
       " 1587,\n",
       " 1590,\n",
       " 1593,\n",
       " 1596,\n",
       " 1599,\n",
       " 1602,\n",
       " 1605,\n",
       " 1608,\n",
       " 1611,\n",
       " 1614,\n",
       " 1617,\n",
       " 1620,\n",
       " 1623,\n",
       " 1626,\n",
       " 1629,\n",
       " 1632,\n",
       " 1635,\n",
       " 1638,\n",
       " 1641,\n",
       " 1644,\n",
       " 1647,\n",
       " 1650,\n",
       " 1653,\n",
       " 1656,\n",
       " 1659,\n",
       " 1662,\n",
       " 1665,\n",
       " 1668,\n",
       " 1671,\n",
       " 1674,\n",
       " 1677,\n",
       " 1680,\n",
       " 1683,\n",
       " 1686,\n",
       " 1689,\n",
       " 1692,\n",
       " 1695,\n",
       " 1698,\n",
       " 1701,\n",
       " 1704,\n",
       " 1707,\n",
       " 1710,\n",
       " 1713,\n",
       " 1716,\n",
       " 1719,\n",
       " 1722,\n",
       " 1725,\n",
       " 1728,\n",
       " 1731,\n",
       " 1734,\n",
       " 1737,\n",
       " 1740,\n",
       " 1743,\n",
       " 1746,\n",
       " 1749,\n",
       " 1752,\n",
       " 1755,\n",
       " 1758,\n",
       " 1761,\n",
       " 1764,\n",
       " 1767,\n",
       " 1770,\n",
       " 1773,\n",
       " 1776,\n",
       " 1779,\n",
       " 1782,\n",
       " 1785,\n",
       " 1788,\n",
       " 1791,\n",
       " 1794,\n",
       " 1797,\n",
       " 1800,\n",
       " 1803,\n",
       " 1806,\n",
       " 1809,\n",
       " 1812,\n",
       " 1815,\n",
       " 1818,\n",
       " 1821,\n",
       " 1824,\n",
       " 1827,\n",
       " 1830,\n",
       " 1833,\n",
       " 1836,\n",
       " 1839,\n",
       " 1842,\n",
       " 1845,\n",
       " 1848,\n",
       " 1851,\n",
       " 1854,\n",
       " 1857,\n",
       " 1860,\n",
       " 1863,\n",
       " 1866,\n",
       " 1869,\n",
       " 1872,\n",
       " 1875,\n",
       " 1878,\n",
       " 1881,\n",
       " 1884,\n",
       " 1887,\n",
       " 1890,\n",
       " 1893,\n",
       " 1896,\n",
       " 1899,\n",
       " 1902,\n",
       " 1905,\n",
       " 1908,\n",
       " 1911,\n",
       " 1914,\n",
       " 1917,\n",
       " 1920,\n",
       " 1923,\n",
       " 1926,\n",
       " 1929,\n",
       " 1932,\n",
       " 1935,\n",
       " 1938,\n",
       " 1941,\n",
       " 1944,\n",
       " 1947,\n",
       " 1950,\n",
       " 1953,\n",
       " 1956,\n",
       " 1959,\n",
       " 1962,\n",
       " 1965,\n",
       " 1968,\n",
       " 1971,\n",
       " 1974,\n",
       " 1977,\n",
       " 1980,\n",
       " 1983,\n",
       " 1986,\n",
       " 1989,\n",
       " 1992,\n",
       " 1995,\n",
       " 1998,\n",
       " 2001,\n",
       " 2004,\n",
       " 2007,\n",
       " 2010,\n",
       " 2013,\n",
       " 2016,\n",
       " 2019,\n",
       " 2022]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base directory: where the SeismicDesignModule package is stored\n",
    "base_directory = 'C:\\\\Users\\\\61946\\\\Documents\\\\GitHub\\\\SeismicDesignModule'\n",
    "\n",
    "# Postprocessing folder path\n",
    "postprocessing_directory = base_directory + '\\\\Postprocessing'\n",
    "\n",
    "# Preprocessing folder path\n",
    "preprocessing_directory = base_directory + '\\\\Preprocessing\\\\SeismicDesign'\n",
    "\n",
    "# Design results folder path\n",
    "design_directory = base_directory + '\\\\BuildingData'\n",
    "\n",
    "# Load the section database\n",
    "os.chdir(base_directory)\n",
    "with open('AllSectionDatabase.csv', 'r') as file:\n",
    "    SECTION_DATABASE = pd.read_csv(file, header=0)\n",
    "\n",
    "# Load the design sampling space\n",
    "os.chdir(preprocessing_directory)\n",
    "with open('DesignSheet2.csv', 'r') as file:\n",
    "    DESIGN_SPACE = pd.read_csv(file, header=0)\n",
    "    \n",
    "# Find the building IDs that we are interested in.\n",
    "target_ID = []\n",
    "except_ID = []\n",
    "row_number = DESIGN_SPACE.shape[0]\n",
    "for indx in range(row_number):\n",
    "    if DESIGN_SPACE.loc[indx, 'number of story'] == 19 and DESIGN_SPACE.loc[indx, 'column beam ratio'] == 1.0 \\\n",
    "    and DESIGN_SPACE.loc[indx, 'number of bay'] != 1 and DESIGN_SPACE.loc[indx, 'building ID'] not in except_ID:\n",
    "        target_ID.append(DESIGN_SPACE.loc[indx, 'building ID'])\n",
    "target_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1539,\n",
       " 1542,\n",
       " 1566,\n",
       " 1569,\n",
       " 1572,\n",
       " 1575,\n",
       " 1578,\n",
       " 1581,\n",
       " 1584,\n",
       " 1587,\n",
       " 1590,\n",
       " 1593,\n",
       " 1596,\n",
       " 1599,\n",
       " 1620,\n",
       " 1623,\n",
       " 1626,\n",
       " 1629,\n",
       " 1632,\n",
       " 1635,\n",
       " 1638,\n",
       " 1641,\n",
       " 1644,\n",
       " 1647,\n",
       " 1650,\n",
       " 1653,\n",
       " 1674,\n",
       " 1677,\n",
       " 1680,\n",
       " 1683,\n",
       " 1686,\n",
       " 1689,\n",
       " 1692,\n",
       " 1695,\n",
       " 1701,\n",
       " 1704,\n",
       " 1707,\n",
       " 1728,\n",
       " 1731,\n",
       " 1734,\n",
       " 1737,\n",
       " 1740,\n",
       " 1743,\n",
       " 1746,\n",
       " 1749,\n",
       " 1755,\n",
       " 1758,\n",
       " 1761,\n",
       " 1782,\n",
       " 1785,\n",
       " 1788,\n",
       " 1791,\n",
       " 1794,\n",
       " 1797,\n",
       " 1800,\n",
       " 1803,\n",
       " 1809,\n",
       " 1812,\n",
       " 1815,\n",
       " 1836,\n",
       " 1839,\n",
       " 1842,\n",
       " 1845,\n",
       " 1848,\n",
       " 1851,\n",
       " 1863,\n",
       " 1866,\n",
       " 1890,\n",
       " 1893,\n",
       " 1896,\n",
       " 1899,\n",
       " 1902,\n",
       " 1905,\n",
       " 1917,\n",
       " 1920,\n",
       " 1944,\n",
       " 1947,\n",
       " 1950,\n",
       " 1953,\n",
       " 1956,\n",
       " 1959,\n",
       " 1971,\n",
       " 1998,\n",
       " 2001,\n",
       " 2004,\n",
       " 2007,\n",
       " 2010,\n",
       " 2013]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify that each building data folder has the same amount of result files\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file_count = []  # Count how many output files each building data folder has\n",
    "desired_ID = []\n",
    "Special_ID = [1698, 1752, 1806, 1854, 1857, 1860, 1908, 1911, 1914, 1962, 1965, 1968, 2016, 2019, 2022]\n",
    "\n",
    "for ID in target_ID:\n",
    "    target_folder = base_directory + '\\\\BuildingData' + '\\\\Building_' + str(ID)\n",
    "    for _, _, files in os.walk(target_folder):\n",
    "        file_count.append(len(files))\n",
    "        if (len(files) != 30):\n",
    "            desired_ID.append(ID)\n",
    "b = []\n",
    "for a in target_ID:\n",
    "    if a not in desired_ID and a not in Special_ID:\n",
    "        b.append(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Sensitivity Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1740, 1794, 1848]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base directory: where the SeismicDesignModule package is stored\n",
    "base_directory = 'C:\\\\Users\\\\XINGQUAN GUAN\\\\Documents\\\\GitHub\\\\SeismicDesignModule'\n",
    "\n",
    "# Postprocessing folder path\n",
    "postprocessing_directory = base_directory + '\\\\Poseprocessing'\n",
    "\n",
    "# Preprocessing folder path\n",
    "preprocessing_directory = base_directory + '\\\\Preprocessing'\n",
    "\n",
    "# Design results folder path\n",
    "design_directory = base_directory + '\\\\BuildingData'\n",
    "\n",
    "# Load the section database\n",
    "os.chdir(base_directory)\n",
    "with open('AllSectionDatabase.csv', 'r') as file:\n",
    "    SECTION_DATABASE = pd.read_csv(file, header=0)\n",
    "\n",
    "# Load the design sampling space\n",
    "os.chdir(preprocessing_directory)\n",
    "with open('DesignSheet2.csv', 'r') as file:\n",
    "    DESIGN_SPACE = pd.read_csv(file, header=0)\n",
    "\n",
    "# Find the building IDs that we are interested in.\n",
    "target_ID = []\n",
    "except_ID = [1545, 1548, 1551, 1554, 1557, 1560, 1563, 1602, 1605, 1608, 1611, 1614, 1617, 1656, 1659, 1662, 1665, 1668,\n",
    "             1671, 1698, 1710, 1713, 1716, 1719, 1722, 1725, \n",
    "             1752, 1764, 1767, 1770, 1773, 1776, 1779, \n",
    "             1806, 1818, 1821, 1824, 1827, 1830, 1833, 1854, 1857, 1860, 1869, 1872, 1875, 1878, 1881, 1884, 1887, \n",
    "             1854, 1857, 1860, 1908, 1911, 1914, 1923, 1926, 1929,\n",
    "             1932, 1935, 1938, 1941, 1962, 1965, 1968, 1974, 1977, 1980, 1983, 1986, 1989, 1992, 1995,\n",
    "             2016, 2019, 2022]\n",
    "row_number = DESIGN_SPACE.shape[0]\n",
    "for indx in range(row_number):\n",
    "    if DESIGN_SPACE.loc[indx, 'number of story'] == 19 and DESIGN_SPACE.loc[indx, 'column beam ratio'] == 1.0 \\\n",
    "    and DESIGN_SPACE.loc[indx, 'building ID'] not in except_ID \\\n",
    "    and DESIGN_SPACE.loc[indx, 'number of bay'] != 1 and DESIGN_SPACE.loc[indx, 'floor dead load'] == 80 \\\n",
    "    and DESIGN_SPACE.loc[indx, 'roof dead load'] == 67.5 \\\n",
    "    and DESIGN_SPACE.loc[indx, 'bay width'] == 30:\n",
    "        target_ID.append(DESIGN_SPACE.loc[indx, 'building ID'])\n",
    "target_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all existing files to new folder\n",
    "starting_ID = 21\n",
    "for ID in target_ID:\n",
    "    source_path = design_directory + \"\\\\Building_\" + str(ID)\n",
    "    # Check if new sensitivity folder exists or not\n",
    "    # If not exist ==> create the folder\n",
    "    dest_path = design_directory + \"\\\\SensitivityBuilding_\" + str(starting_ID)\n",
    "    if not os.path.exists(dest_path):\n",
    "        os.makedirs(dest_path)\n",
    "    # Copy all current files into sensitivity building folder\n",
    "    os.chdir(source_path)\n",
    "    for _, _, file in os.walk(source_path):\n",
    "        for single_file in file:\n",
    "            dest_file = dest_path + \"\\\\\" + single_file\n",
    "            shutil.copy(single_file, dest_file)\n",
    "    starting_ID += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Sensitivity Study Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base directory: where the SeismicDesignModule package is stored\n",
    "base_directory = 'C:\\\\Users\\\\XINGQUAN GUAN\\\\Documents\\\\GitHub\\\\SeismicDesignModule'\n",
    "\n",
    "# Postprocessing folder path\n",
    "postprocessing_directory = base_directory + '\\\\Poseprocessing'\n",
    "\n",
    "# Preprocessing folder path\n",
    "preprocessing_directory = base_directory + '\\\\Preprocessing'\n",
    "\n",
    "# Design results folder path\n",
    "design_directory = base_directory + '\\\\BuildingData'\n",
    "\n",
    "# Create Sensitivity Study Building Folder of Drift\n",
    "target_IDs = list(range(0, 24))\n",
    "file_list = ['ELFParameters.csv', 'Geometry.csv', 'Loads.csv', 'MemberDepth.csv']\n",
    "for ID in target_IDs:\n",
    "    source_path = design_directory + '\\\\SensitivityBuilding_' + str(ID)\n",
    "    dest_folder = design_directory + '\\\\SensitivityBuilding_' + str(ID) + '_ExtIntCol10'\n",
    "    if not os.path.exists(dest_folder):\n",
    "        os.makedirs(dest_folder)\n",
    "    os.chdir(source_path)\n",
    "    for file in file_list:\n",
    "        dest_file = dest_folder + '\\\\' + file\n",
    "        shutil.copy(file, dest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Base directory: where the SeismicDesignModule package is stored\n",
    "base_directory = 'C:\\\\Users\\\\XINGQUAN GUAN\\\\Documents\\\\GitHub\\\\SeismicDesignModule'\n",
    "\n",
    "# Postprocessing folder path\n",
    "postprocessing_directory = base_directory + '\\\\Poseprocessing'\n",
    "\n",
    "# Preprocessing folder path\n",
    "preprocessing_directory = base_directory + '\\\\Preprocessing'\n",
    "\n",
    "# Design results folder path\n",
    "design_directory = base_directory + '\\\\BuildingData'\n",
    "\n",
    "# Load the section database\n",
    "os.chdir(base_directory)\n",
    "with open('AllSectionDatabase.csv', 'r') as file:\n",
    "    SECTION_DATABASE = pd.read_csv(file, header=0)\n",
    "\n",
    "# Load the design sampling space\n",
    "os.chdir(preprocessing_directory)\n",
    "with open('DesignSheet2.csv', 'r') as file:\n",
    "    DESIGN_SPACE = pd.read_csv(file, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desired_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
